{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output_file_2.txt', 'r', encoding='utf-8') as file:\n",
    "    data = [json.loads(line.strip()) for line in file]\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chapter_df(df):\n",
    "    # Select columns: 'enchapter', 'enchapter_notes', 'kochapter_notes'\n",
    "    df = df.loc[:, ['ensection','enchapter', 'enchapter_notes', 'kochapter_notes']]\n",
    "    # Drop duplicate rows across all columns\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "chapter_df = create_chapter_df(df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fix_atag(html):\n",
    "    # Phân tích cú pháp HTML\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Duyệt qua tất cả thẻ <a>\n",
    "    for a_tag in soup.find_all('a'):\n",
    "        # Kiểm tra nếu thẻ <a> chứa <img>\n",
    "        if a_tag.find('img'):\n",
    "            attributes_to_remove = ['rel', 'href', 'title']\n",
    "            for attr in attributes_to_remove:\n",
    "                if attr in a_tag.attrs:  \n",
    "                    del a_tag[attr]\n",
    "                if 'alt' in a_tag.find('img').attrs:  \n",
    "                    del a_tag.find('img')['alt']\n",
    "            \n",
    "        else:\n",
    "            # Thay thẻ <a> bằng text bên trong nó\n",
    "            a_tag.replace_with(a_tag.text)\n",
    "\n",
    "    # Kết quả sau khi xử lý\n",
    "    result = str(soup).replace('\"/clip/','\"https://unipass.customs.go.kr/clip/')\n",
    "    # print(result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chapter_notes(df,en_col,ko_col):\n",
    "    \n",
    "    def split_text(text):\n",
    "        if not isinstance(text, str):\n",
    "            return []\n",
    "        text = text.replace('\\n \\n', '\\n\\n')\n",
    "        text = text.replace('_x000D__x000D_', '\\n')\n",
    "        # Thay thế 3 hoặc nhiều '\\n' thành '\\n\\n'\n",
    "        text = re.sub(r'\\n{2,}', '\\n', text)\n",
    "        delimiter = '\\n'\n",
    "        parts = text.split(delimiter)\n",
    "        # print(parts)\n",
    "        return parts\n",
    "    \n",
    "    def get_note_index(parts):\n",
    "        note_pattern_en = r'^Notes?\\.$'\n",
    "        note_pattern_ko = r'^주:\\s*'\n",
    "        # Tìm các vị trí phần tử khớp với regex\n",
    "        note_index = next((i for i, item in enumerate(parts) if re.fullmatch(note_pattern_en, item.replace('\\n','').strip()) or re.fullmatch(note_pattern_ko, item.replace('\\n','').strip())), None)\n",
    "        # print(\"note_index: \",note_index)\n",
    "        return note_index\n",
    "    \n",
    "    def get_general_index(parts):\n",
    "        general_pattern_en = r'^GENERAL\\.*$'\n",
    "        general_pattern_ko = r'^총설\\s*$'\n",
    "        general_index = next((i for i, item in enumerate(parts) if re.fullmatch(general_pattern_en, item.replace('\\n','').strip())or re.fullmatch(general_pattern_ko, item.replace('\\n','').strip())), None)\n",
    "        # print('general_index: ',general_index)\n",
    "        return general_index\n",
    "    \n",
    "    def process_notes(x):\n",
    "        split = split_text(x)\n",
    "        note_idx = get_note_index(split)\n",
    "        general_idx = get_general_index(split)\n",
    "        if note_idx is None:\n",
    "            return []\n",
    "        elif general_idx is not None:\n",
    "            return split[note_idx:general_idx]\n",
    "        else:\n",
    "            return split[note_idx:]\n",
    "    \n",
    "    def process_general(x):\n",
    "        split = split_text(x)\n",
    "        general_idx = get_general_index(split)\n",
    "        if general_idx is None:\n",
    "            return []\n",
    "        elif general_idx is not None:\n",
    "            return split[general_idx:]\n",
    "        \n",
    "    def process_des(x):\n",
    "        split = split_text(x)\n",
    "        note_idx = get_note_index(split)\n",
    "        if note_idx is None:\n",
    "            return split[1:]\n",
    "        elif note_idx is not None:\n",
    "            return split[1:note_idx]\n",
    "        \n",
    "    def int_to_roman(num):\n",
    "        num = int(num)\n",
    "        roman_numerals = [\n",
    "            (\"M\", 1000), (\"CM\", 900), (\"D\", 500), (\"CD\", 400),\n",
    "            (\"C\", 100), (\"XC\", 90), (\"L\", 50), (\"XL\", 40),\n",
    "            (\"X\", 10), (\"IX\", 9), (\"V\", 5), (\"IV\", 4),\n",
    "            (\"I\", 1)\n",
    "        ]\n",
    "        \n",
    "        result = \"\"\n",
    "        for roman, value in roman_numerals:\n",
    "            while num >= value:\n",
    "                result += roman\n",
    "                num -= value\n",
    "        return result\n",
    "\n",
    "    # Áp dụng hàm\n",
    "    df['chapter_name'] = df[en_col].apply(lambda x: split_text(x)[0])\n",
    "    df['en_description'] = df[en_col].apply(process_des)\n",
    "    df['ko_description'] = df[ko_col].apply(process_des)\n",
    "    \n",
    "    df['en_notes'] = df[en_col].apply(process_notes)\n",
    "    \n",
    "    df['ko_notes'] = df[ko_col].apply(process_notes)\n",
    "    \n",
    "    df['en_general'] = df[en_col].apply(process_general)\n",
    "    df['ko_general'] = df[ko_col].apply(process_general)\n",
    "    df['_nest_parent_'] = df['ensection'].apply(int_to_roman)\n",
    "    df.insert(5, \"hs\", df[\"enchapter\"])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gọi hàm xử lý\n",
    "chapter_df = process_chapter_notes(chapter_df, 'enchapter_notes', 'kochapter_notes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_df = chapter_df.drop(columns=['ensection','enchapter_notes', 'kochapter_notes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nguye\\AppData\\Local\\Temp\\ipykernel_4144\\4206761639.py:5: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html, 'html.parser')\n"
     ]
    }
   ],
   "source": [
    "chapter_df['ko_notes'] = chapter_df['ko_notes'].apply(lambda x: [fix_atag(html) for html in x])\n",
    "chapter_df['ko_general'] = chapter_df['ko_general'].apply(lambda x: [fix_atag(html) for html in x])\n",
    "chapter_df['en_notes'] = chapter_df['en_notes'].apply(lambda x: [fix_atag(html) for html in x])\n",
    "chapter_df['en_general'] = chapter_df['en_general'].apply(lambda x: [fix_atag(html) for html in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enchapter</th>\n",
       "      <th>chapter_name</th>\n",
       "      <th>hs</th>\n",
       "      <th>en_description</th>\n",
       "      <th>ko_description</th>\n",
       "      <th>en_notes</th>\n",
       "      <th>ko_notes</th>\n",
       "      <th>en_general</th>\n",
       "      <th>ko_general</th>\n",
       "      <th>_nest_parent_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>Chapter 1</td>\n",
       "      <td>01</td>\n",
       "      <td>[Live animals]</td>\n",
       "      <td>[살아 있는 동물]</td>\n",
       "      <td>[Note. , 1.- This Chapter covers all live anim...</td>\n",
       "      <td>[주: , 1. 이 류에는 다음 각 목의 것을 제외한 모든 살아 있는 동물이 포함된...</td>\n",
       "      <td>[GENERAL, This Chapter covers all living creat...</td>\n",
       "      <td>[총설, 이 류에는 다음의 것을 제외한 모든 살아 있는 동물(식용이나 그 밖의 용도...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>02</td>\n",
       "      <td>Chapter 2</td>\n",
       "      <td>02</td>\n",
       "      <td>[Meat and edible meat offal ]</td>\n",
       "      <td>[육과 식용 설육(屑肉)]</td>\n",
       "      <td>[Note., 1.-  This Chapter does not cover :, (a...</td>\n",
       "      <td>[주: , 1. 이 류에서 다음 각 목의 것은 제외한다., 가. 제0201호부터 제...</td>\n",
       "      <td>[GENERAL, This Chapter applies to meat in carc...</td>\n",
       "      <td>[총설, 이 류에는 식용에 적합한 모든 동물[제3류의 어류․갑각류․연체동물․그 밖의...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  enchapter chapter_name  hs                 en_description  ko_description  \\\n",
       "0        01    Chapter 1  01                 [Live animals]      [살아 있는 동물]   \n",
       "6        02    Chapter 2  02  [Meat and edible meat offal ]  [육과 식용 설육(屑肉)]   \n",
       "\n",
       "                                            en_notes  \\\n",
       "0  [Note. , 1.- This Chapter covers all live anim...   \n",
       "6  [Note., 1.-  This Chapter does not cover :, (a...   \n",
       "\n",
       "                                            ko_notes  \\\n",
       "0  [주: , 1. 이 류에는 다음 각 목의 것을 제외한 모든 살아 있는 동물이 포함된...   \n",
       "6  [주: , 1. 이 류에서 다음 각 목의 것은 제외한다., 가. 제0201호부터 제...   \n",
       "\n",
       "                                          en_general  \\\n",
       "0  [GENERAL, This Chapter covers all living creat...   \n",
       "6  [GENERAL, This Chapter applies to meat in carc...   \n",
       "\n",
       "                                          ko_general _nest_parent_  \n",
       "0  [총설, 이 류에는 다음의 것을 제외한 모든 살아 있는 동물(식용이나 그 밖의 용도...             I  \n",
       "6  [총설, 이 류에는 식용에 적합한 모든 동물[제3류의 어류․갑각류․연체동물․그 밖의...             I  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapter_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_df.to_excel(\"ko_en_chapter_notes_2024.xlsx\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
