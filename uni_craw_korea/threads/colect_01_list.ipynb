{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl.styles import Alignment\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import concurrent.futures\n",
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detailinforequest(rrdcNo):\n",
    "# URL của API\n",
    "    url = 'https://unipass.customs.go.kr/clip/prlstclsfsrch/retrieveDmstPrlstClsfCaseDtl.do'\n",
    "\n",
    "    # Headers\n",
    "    headers = {\n",
    "        'Accept': 'text/html, */*; q=0.01',\n",
    "        'Accept-Language': 'en-US,en;q=0.9,vi;q=0.8,vi-VN;q=0.7',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',\n",
    "        'Cookie': 'WMONID=N_4A3dINH0I; JSESSIONID=0001O2y8S-yyQQ_lga-knblPV6Lb2QN6662ivRFJ_jK2FPRlLOTKNEsnuhZe_QxBEKq-8U03_kah8EgUgb-_Exa4dmevvhJHEKeNuIq9prRxpJht6ugFASENgz3p_AdMPw4_:eul21',\n",
    "        'DNT': '1',\n",
    "        'Origin': 'https://unipass.customs.go.kr',\n",
    "        'Referer': 'https://unipass.customs.go.kr/clip/index.do',\n",
    "        'Sec-Fetch-Dest': 'empty',\n",
    "        'Sec-Fetch-Mode': 'cors',\n",
    "        'Sec-Fetch-Site': 'same-origin',\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36',\n",
    "        'X-Requested-With': 'XMLHttpRequest',\n",
    "        'isAjax': 'true',\n",
    "        'sec-ch-ua': '\"Google Chrome\";v=\"129\", \"Not=A?Brand\";v=\"8\", \"Chromium\";v=\"129\"',\n",
    "        'sec-ch-ua-mobile': '?0',\n",
    "        'sec-ch-ua-platform': '\"Windows\"'\n",
    "    }\n",
    "\n",
    "    # Dữ liệu trong body của yêu cầu\n",
    "    payload = {\n",
    "        'rrdcNo': rrdcNo\n",
    "    }\n",
    "\n",
    "    # Gửi yêu cầu POST với headers và dữ liệu body\n",
    "    response = requests.post(url, headers=headers, data=payload)\n",
    "    \n",
    "    # Kiểm tra phản hồi từ API\n",
    "    if response.status_code == 200:\n",
    "        return response.text  \n",
    "    else:\n",
    "        print(rrdcNo + \"Lỗi\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Hàm trích xuất các thành phần từ HTML\n",
    "def extract_data_from_html(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Tìm các thành phần theo nhãn <tr> và trích xuất giá trị\n",
    "    ref_no = soup.find('th', text='참조번호').find_next_sibling('td').text.strip()\n",
    "    implementation_date = soup.find('th', text='시행일자').find_next_sibling('td').text.strip()\n",
    "    implementing_agency = soup.find('th', text='시행기관').find_next_sibling('td').text.strip()\n",
    "\n",
    "    # Chỉ lấy phần đầu tiên của quyết định (trước dấu xuống dòng \\n)\n",
    "    decision_code = soup.find('th', text='결정세번').find_next_sibling('td').find('input')['value'].strip()\n",
    "\n",
    "    product_name_html = soup.find('th', text='품명').find_next_sibling('td')\n",
    "    for elem in product_name_html(True):\n",
    "        if elem.name == 'a':  # Đổi thẻ <a> thành văn bản\n",
    "            elem.replace_with(elem.text)\n",
    "        elif elem.name == 'br':  # Giữ lại thẻ <br>\n",
    "            continue\n",
    "    product_name = product_name_html.decode_contents().replace('\\r', '').replace('\\t', '').replace('\\n', '').strip()\n",
    "\n",
    "    product_description_html = soup.find('th', text='물품설명').find_next_sibling('td')\n",
    "    for elem in product_description_html(True):\n",
    "        if elem.name == 'a':  # Đổi thẻ <a> thành văn bản\n",
    "            elem.replace_with(elem.text)\n",
    "        elif elem.name == 'br':  # Giữ lại thẻ <br>\n",
    "            continue\n",
    "    product_description = product_description_html.decode_contents().replace('\\r', '').replace('\\t', '').replace('\\n', '').strip()    \n",
    "        \n",
    "    decision_reason_html = soup.find('th', text='결정사유').find_next_sibling('td')\n",
    "    for elem in decision_reason_html(True):\n",
    "        if elem.name == 'a':  # Đổi thẻ <a> thành văn bản\n",
    "            elem.replace_with(elem.text)\n",
    "        elif elem.name == 'br':  # Giữ lại thẻ <br>\n",
    "            continue\n",
    "    decision_reason = decision_reason_html.decode_contents().replace('\\r', '').replace('\\t', '').replace('\\n', '').strip()    \n",
    "\n",
    "    image_count = soup.find('th', text='이미지건수').find_next_sibling('td').text.strip()\n",
    "    # Liệt kê các hình ảnh trong mục \"관련 이미지\"\n",
    "    image_elements = soup.find('th', text='관련 이미지').find_next_sibling('td').find_all('img')\n",
    "    image_links = [img['src'] for img in image_elements]\n",
    "\n",
    "    # Tạo kết quả dưới dạng dictionary\n",
    "    result = {\n",
    "        \"참조번호\": ref_no,\n",
    "        \"시행일자\": implementation_date,\n",
    "        \"시행기관\": implementing_agency,\n",
    "        \"결정세번\": decision_code,\n",
    "        \"품명\": product_name,\n",
    "        \"물품설명\": product_description,\n",
    "        \"결정사유\": decision_reason,\n",
    "        \"이미지건수\": image_count,\n",
    "        \"관련 이미지\": image_links\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26626\n"
     ]
    }
   ],
   "source": [
    "list_file = \"01_list.txt\"\n",
    "\n",
    "with open(list_file, 'r', encoding='utf-8') as file:\n",
    "    content = file.read()  # Đọc toàn bộ nội dung file\n",
    "\n",
    "# Chia nhỏ theo dấu cách hoặc dấu phân cách khác\n",
    "data_list = content.split()  # Chia nhỏ theo dấu cách (space)\n",
    "\n",
    "print(len(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nguye\\AppData\\Local\\Temp\\ipykernel_10548\\982939226.py:6: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  ref_no = soup.find('th', text='참조번호').find_next_sibling('td').text.strip()\n",
      "C:\\Users\\nguye\\AppData\\Local\\Temp\\ipykernel_10548\\982939226.py:7: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  implementation_date = soup.find('th', text='시행일자').find_next_sibling('td').text.strip()\n",
      "C:\\Users\\nguye\\AppData\\Local\\Temp\\ipykernel_10548\\982939226.py:8: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  implementing_agency = soup.find('th', text='시행기관').find_next_sibling('td').text.strip()\n",
      "C:\\Users\\nguye\\AppData\\Local\\Temp\\ipykernel_10548\\982939226.py:11: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  decision_code = soup.find('th', text='결정세번').find_next_sibling('td').find('input')['value'].strip()\n",
      "C:\\Users\\nguye\\AppData\\Local\\Temp\\ipykernel_10548\\982939226.py:13: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  product_name_html = soup.find('th', text='품명').find_next_sibling('td')\n",
      "C:\\Users\\nguye\\AppData\\Local\\Temp\\ipykernel_10548\\982939226.py:21: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  product_description_html = soup.find('th', text='물품설명').find_next_sibling('td')\n",
      "C:\\Users\\nguye\\AppData\\Local\\Temp\\ipykernel_10548\\982939226.py:29: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  decision_reason_html = soup.find('th', text='결정사유').find_next_sibling('td')\n",
      "C:\\Users\\nguye\\AppData\\Local\\Temp\\ipykernel_10548\\982939226.py:37: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  image_count = soup.find('th', text='이미지건수').find_next_sibling('td').text.strip()\n",
      "C:\\Users\\nguye\\AppData\\Local\\Temp\\ipykernel_10548\\982939226.py:39: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  image_elements = soup.find('th', text='관련 이미지').find_next_sibling('td').find_all('img')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 0082001815127: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Read timed out. (read timeout=None)\n",
      "Error processing 0072004871023: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Max retries exceeded with url: /clip/prlstclsfsrch/retrieveDmstPrlstClsfCaseDtl.do (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001DB623B8110>, 'Connection to unipass.customs.go.kr timed out. (connect timeout=None)'))\n",
      "Error processing 0072018002145: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Read timed out. (read timeout=None)\n",
      "Error processing 0081995811845: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Read timed out. (read timeout=None)\n",
      "Error processing 0072014002432: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Read timed out. (read timeout=None)\n",
      "Error processing 0072011000548: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Max retries exceeded with url: /clip/prlstclsfsrch/retrieveDmstPrlstClsfCaseDtl.do (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001DB62AF4BF0>, 'Connection to unipass.customs.go.kr timed out. (connect timeout=None)'))\n",
      "Error processing 0072015005789: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Max retries exceeded with url: /clip/prlstclsfsrch/retrieveDmstPrlstClsfCaseDtl.do (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001DB6251E720>, 'Connection to unipass.customs.go.kr timed out. (connect timeout=None)'))\n",
      "Error processing 0072017000720: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Max retries exceeded with url: /clip/prlstclsfsrch/retrieveDmstPrlstClsfCaseDtl.do (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001DB62AF42F0>, 'Connection to unipass.customs.go.kr timed out. (connect timeout=None)'))\n",
      "Error processing 0082001812492: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Max retries exceeded with url: /clip/prlstclsfsrch/retrieveDmstPrlstClsfCaseDtl.do (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001DB62362840>, 'Connection to unipass.customs.go.kr timed out. (connect timeout=None)'))\n",
      "Error processing 0072013002346: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Max retries exceeded with url: /clip/prlstclsfsrch/retrieveDmstPrlstClsfCaseDtl.do (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001DB628A4A10>, 'Connection to unipass.customs.go.kr timed out. (connect timeout=None)'))\n",
      "Error processing 0072021001756: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Max retries exceeded with url: /clip/prlstclsfsrch/retrieveDmstPrlstClsfCaseDtl.do (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001DB6238E840>, 'Connection to unipass.customs.go.kr timed out. (connect timeout=None)'))\n",
      "Error processing 0072023000271: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Max retries exceeded with url: /clip/prlstclsfsrch/retrieveDmstPrlstClsfCaseDtl.do (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001DB628A6930>, 'Connection to unipass.customs.go.kr timed out. (connect timeout=None)'))\n",
      "Error processing 0001991804355: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Max retries exceeded with url: /clip/prlstclsfsrch/retrieveDmstPrlstClsfCaseDtl.do (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001DB62D1F320>, 'Connection to unipass.customs.go.kr timed out. (connect timeout=None)'))\n",
      "Error processing 0072016004053: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Max retries exceeded with url: /clip/prlstclsfsrch/retrieveDmstPrlstClsfCaseDtl.do (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001DB62E95340>, 'Connection to unipass.customs.go.kr timed out. (connect timeout=None)'))\n",
      "Error processing 0072013003685: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Max retries exceeded with url: /clip/prlstclsfsrch/retrieveDmstPrlstClsfCaseDtl.do (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001DB6285D460>, 'Connection to unipass.customs.go.kr timed out. (connect timeout=None)'))\n",
      "Error processing 0072017007803: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Max retries exceeded with url: /clip/prlstclsfsrch/retrieveDmstPrlstClsfCaseDtl.do (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001DB62501550>, 'Connection to unipass.customs.go.kr timed out. (connect timeout=None)'))\n",
      "Error processing 0001988806894: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Max retries exceeded with url: /clip/prlstclsfsrch/retrieveDmstPrlstClsfCaseDtl.do (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001DB62E969C0>, 'Connection to unipass.customs.go.kr timed out. (connect timeout=None)'))\n",
      "Error processing 0072011001171: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Max retries exceeded with url: /clip/prlstclsfsrch/retrieveDmstPrlstClsfCaseDtl.do (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001DB62C20650>, 'Connection to unipass.customs.go.kr timed out. (connect timeout=None)'))\n",
      "Error processing 0072023001819: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Read timed out. (read timeout=None)\n",
      "Error processing 0072014003606: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Read timed out. (read timeout=None)\n",
      "Error processing 0072015002505: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error processing 0072018004415: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error processing 0082002801065: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Read timed out. (read timeout=None)\n",
      "Error processing 0072016007413: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error processing 0072014000129: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Read timed out. (read timeout=None)\n",
      "Error processing 0072011000019: HTTPSConnectionPool(host='unipass.customs.go.kr', port=443): Read timed out. (read timeout=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Thư mục để lưu trạng thái và kết quả\n",
    "output_dir = \"output01\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# File để lưu trạng thái của vòng lặp\n",
    "state_file_template = os.path.join(output_dir, \"loop_state_{}.json\")\n",
    "output_file_template = os.path.join(output_dir, \"output_data_{}.txt\")\n",
    "final_output_file = \"final_output_data_01.txt\"  # File tổng kết quả\n",
    "\n",
    "# Hàm để lưu trạng thái\n",
    "def save_state(states, thread_index):\n",
    "    with open(state_file_template.format(thread_index), \"w\") as f:\n",
    "        json.dump(states, f)\n",
    "\n",
    "# Hàm để tải trạng thái\n",
    "def load_state(thread_index):\n",
    "    try:\n",
    "        with open(state_file_template.format(thread_index), \"r\") as f:\n",
    "            states = json.load(f)\n",
    "            return states\n",
    "    except FileNotFoundError:\n",
    "        return 0  # Nếu không tìm thấy file, bắt đầu từ đầu\n",
    "\n",
    "# Hàm xử lý từng phần dữ liệu\n",
    "def process_data_chunk(data_chunk, thread_index, start_index):\n",
    "    all_detail_output = []\n",
    "    current_index = start_index\n",
    "\n",
    "    for rrdcNo in data_chunk:\n",
    "        try:\n",
    "            # Xử lý logic chính\n",
    "            html_content = detailinforequest(rrdcNo)\n",
    "            detail_output = extract_data_from_html(html_content)\n",
    "            all_detail_output.append(detail_output)\n",
    "\n",
    "            # Lưu trạng thái sau mỗi lần xử lý\n",
    "            current_index += 1\n",
    "            \n",
    "            # Ghi kết quả vào file riêng cho thread\n",
    "            with open(output_file_template.format(thread_index), \"a\", encoding='utf-8') as f:\n",
    "                f.write(json.dumps(detail_output, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {rrdcNo}: {e}\")\n",
    "            # Lưu trạng thái ngay cả khi có lỗi\n",
    "            save_state(current_index, thread_index)  # Cập nhật trạng thái ngay cả khi có lỗi\n",
    "            break  # Dừng lại nếu có lỗi để không làm hỏng chunk này\n",
    "\n",
    "        # Lưu trạng thái\n",
    "        save_state(current_index, thread_index)\n",
    "\n",
    "    return all_detail_output, current_index\n",
    "\n",
    "# Bắt đầu vòng lặp từ trạng thái đã lưu\n",
    "saved_states = [load_state(i) for i in range(54)]  # Giả sử có 54 threads\n",
    "chunk_size = 500\n",
    "data_chunks = [data_list[i:i + chunk_size] for i in range(0, len(data_list), chunk_size)]\n",
    "\n",
    "# Sử dụng multithreading để xử lý từng chunk\n",
    "all_results = []\n",
    "states = {}\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=54) as executor:\n",
    "    futures = {\n",
    "        executor.submit(process_data_chunk, chunk, idx, saved_states[idx]): idx\n",
    "        for idx, chunk in enumerate(data_chunks)\n",
    "    }\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        thread_index = futures[future]\n",
    "        try:\n",
    "            results, current_index = future.result()\n",
    "            all_results.extend(results)\n",
    "            states[thread_index] = current_index  # Lưu trạng thái của thread\n",
    "        except Exception as e:\n",
    "            print(f\"Thread {thread_index} encountered an error: {e}\")\n",
    "            # Nếu gặp lỗi trong thread, vẫn lưu trạng thái\n",
    "            save_state(states, thread_index)\n",
    "\n",
    "# Ghi tất cả kết quả vào file tổng sau khi hoàn thành\n",
    "with open(final_output_file, \"w\", encoding='utf-8') as f:\n",
    "    for thread_index in range(54):\n",
    "        with open(output_file_template.format(thread_index), \"r\", encoding='utf-8') as thread_file:\n",
    "            for line in thread_file:\n",
    "                f.write(line)\n",
    "\n",
    "# # Ghi trạng thái cuối cùng sau khi tất cả các chunk đã xử lý\n",
    "# for i in range(54):\n",
    "#     save_state(states, i)  # Cập nhật trạng thái cuối cùng cho từng thread\n",
    "# final_state_file = os.path.join(output_dir, \"final_loop_state.json\")\n",
    "\n",
    "final_state_file = os.path.join(output_dir, \"final_loop_state.json\")\n",
    "# Hàm để lưu trạng thái tổng hợp\n",
    "def save_final_state(states):\n",
    "    with open(final_state_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(states, f, ensure_ascii=False, indent=4)\n",
    "# Ghi trạng thái cuối cùng sau khi tất cả các chunk đã xử lý\n",
    "save_final_state(states)  # Ghi toàn bộ trạng thái của các thread vào file tổng hợp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu đã được ghi vào file Excel thành công!\n"
     ]
    }
   ],
   "source": [
    "# Đường dẫn đến file TXT chứa dữ liệu\n",
    "input_file = 'final_output_data_01.txt'\n",
    "# Đường dẫn đến file Excel mà bạn muốn tạo\n",
    "output_file = '01.xlsx'\n",
    "\n",
    "# Danh sách để lưu các dict\n",
    "data_list = []\n",
    "\n",
    "# Đọc dữ liệu từ file TXT\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        # Chuyển đổi mỗi dòng thành dict và thêm vào danh sách\n",
    "        data_list.append(json.loads(line.strip()))\n",
    "\n",
    "# Tạo DataFrame từ danh sách dict\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Ghi DataFrame vào file Excel\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"Dữ liệu đã được ghi vào file Excel thành công!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
